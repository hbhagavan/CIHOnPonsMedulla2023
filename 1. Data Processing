# title: "1. Data Processing"
# author: Hemalatha Bhagavan, PhD [Center for Integrative Brain Research, Seattle Childrenâ€™s Research Institute]

# load libraries 
library(Seurat)
library(tidyverse)
library(Matrix)
library(scales)
library(cowplot)
library(RCurl)

# Load dataset 
for(file in c("CIH_C1_soupX_filt","CIH_C2_soupX_filt","CIH_C4_soupX_filt","CIH_T1_soupX_filt","CIH_T2_soupX_filt","CIH_T4_soupX_filt")){
  # read 10x
  count <- Read10X(data.dir = paste0("./data/",file))
  cells_per_genes <- rowSums(count > 0)
  keep_cells <- which(cells_per_genes>=10)
  count_mod <- count[keep_cells,]
  seurat_obj <- CreateSeuratObject(counts = count_mod,
                                   min.features = 250,
                                   min.cells = 5,
                                   project = file,
                                   names.field = 1,
                                   names.delim = "_",)
  assign(file, seurat_obj)
}



# Fixing the column names to include 'cell_index' and setting sample and condition information

CIH_C1_soupX_filt@meta.data$cell_index <- colnames(CIH_C1_soupX_filt)
CIH_C2_soupX_filt@meta.data$cell_index <- colnames(CIH_C2_soupX_filt)
CIH_C4_soupX_filt@meta.data$cell_index <- colnames(CIH_C4_soupX_filt)

CIH_T1_soupX_filt@meta.data$cell_index <- colnames(CIH_T1_soupX_filt)
CIH_T2_soupX_filt@meta.data$cell_index <- colnames(CIH_T2_soupX_filt)
CIH_T4_soupX_filt@meta.data$cell_index <- colnames(CIH_T4_soupX_filt)

#fix the C1 files
CIH_C1_soupX_filt@meta.data$sample_id <- "C1"
CIH_C1_soupX_filt@meta.data$condition <- "control"

#fix the C2 files
CIH_C2_soupX_filt@meta.data$sample_id <- "C2"
CIH_C2_soupX_filt@meta.data$condition <- "control"

#fix the C3 files
CIH_C4_soupX_filt@meta.data$sample_id <- "C3"
CIH_C4_soupX_filt@meta.data$condition <- "control"

#fix the T1 files
CIH_T1_soupX_filt@meta.data$sample_id <- "T1"
CIH_T1_soupX_filt@meta.data$condition <- "stimulated"

#fix the T1 files
CIH_T2_soupX_filt@meta.data$sample_id <- "T2"
CIH_T2_soupX_filt@meta.data$condition <- "stimulated"

#fix the T1 files
CIH_T4_soupX_filt@meta.data$sample_id <- "T3"
CIH_T4_soupX_filt@meta.data$condition <- "stimulated"

#Create a merged seurat object
merged_seurat <- merge(x = CIH_C1_soupX_filt, 
                       y = c(CIH_C2_soupX_filt, CIH_C4_soupX_filt, CIH_T1_soupX_filt, CIH_T2_soupX_filt, CIH_T4_soupX_filt),
                       add.cell.id = c("ctrl","ctrl","ctrl","stim","stim","stim"))



# Find mitochondrial genes and calculate percent mitochondrial content
# Plot some quality control metrics
# Finds MT genes, 13 expected
grep("^mt-", rownames(merged_seurat), value = TRUE)

#calculating percent mito
merged_seurat[["percent.mt"]]<- PercentageFeatureSet(merged_seurat, pattern ="^mt-")

VlnPlot(merged_seurat, c("nCount_RNA", "nFeature_RNA", "percent.mt"), group.by = "sample_id",
        pt.size = 0)

# Filter cells based on specified criteria
filtered_seurat <- subset(merged_seurat, subset = nFeature_RNA > 1500 & nFeature_RNA < 5500 & percent.mt < 2)

# split the merged files by sample_id
split_seurat <- SplitObject(filtered_seurat, split.by = "sample_id")

# Load required libraries
library(parallel) 
library(DoubletFinder)

# Identify doublets using DoubletFinder
# This section loops through the samples to find doublets for each one

# loop through samples to find doublets
for (i in 1:length(split_seurat)){
  
  # Pre-process seurat object with standard seurat workflow
  print(split_seurat[i])
  split_seuratt <- split_seurat[[i]]
  split_seuratt <- NormalizeData(split_seuratt)
  split_seuratt <- FindVariableFeatures(split_seuratt,selection.method = "vst", nfeatures = 2000)
  split_seuratt <- ScaleData(split_seuratt)
  split_seuratt <- RunPCA(split_seuratt,features = VariableFeatures(object = split_seuratt))
  
  # finish pre-processing
  
  split_seuratt <- FindNeighbors(object = split_seuratt, dims = 1:20)              
  split_seuratt <- FindClusters(object = split_seuratt, resolution = 0.1)
  split_seuratt <- RunUMAP(split_seuratt, dims = 1:20)
  
  # pK identification (no ground-truth)
  sweep.list <- paramSweep_v3(split_seuratt, PCs = 1:20)
  sweep.stats <- summarizeSweep(sweep.list)
  bcmvn <- find.pK(sweep.stats)
  
  print(paste0("Sample complete step ",1))
  
    # Optimal pK is the max of the bomodality coefficent (BCmvn) distribution
  bcmvn.max <- bcmvn[which.max(bcmvn$BCmetric),]
  optimal.pk <- bcmvn.max$pK
  optimal.pk <- as.numeric(levels(optimal.pk))[optimal.pk]
  
  print(paste0("Sample complete step ",2))
  
  
  ## Homotypic doublet proportion estimate
  annotations <- split_seuratt@meta.data$seurat_clusters
  homotypic.prop <- modelHomotypic(annotations) 
  nExp.poi <- round(optimal.pk * nrow(split_seuratt@meta.data)) ## Assuming 7.5% doublet formation rate - tailor for your dataset
  nExp.poi.adj <- round(nExp.poi * (1 - homotypic.prop))
  
  print(paste0("Sample complete step ",3))

  # run doubletFinder 
  split_seuratt <- doubletFinder_v3(split_seuratt, 
                                    PCs = 1:20, 
                                    pK = optimal.pk,
                                    nExp = nExp.poi.adj)
  
  print(paste0("steps competed ",4))
  
  split_seurat[[i]] <- split_seuratt
  print(paste0("All steps competed ",5))
  
}

# save the data file
# remove doublets from the files

# Normalize the data using the glmGamPoi method for each sample
library(glmGamPoi)

for (i in 1:length(split_seurat)) {
  split_seurat[[i]] <- SCTransform(split_seurat[[i]], 
                                   method = "glmGamPoi", 
                                   vars.to.regress = c("percent.mt"))
}

# save the data file
